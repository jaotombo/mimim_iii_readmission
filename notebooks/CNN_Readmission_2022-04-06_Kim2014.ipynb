{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "data = pd.read_feather('../Data/df_cleaned_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import spacy\n",
    "import fr_core_news_md\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Flatten, concatenate, Activation, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather('../Data/df_cleaned_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42825 entries, 0 to 42824\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   index            42825 non-null  int64         \n",
      " 1   subject_id       42825 non-null  int64         \n",
      " 2   hadm_id          42825 non-null  int64         \n",
      " 3   admittime        42825 non-null  datetime64[ns]\n",
      " 4   dischtime        42825 non-null  datetime64[ns]\n",
      " 5   first_careunit   42825 non-null  object        \n",
      " 6   last_careunit    42825 non-null  object        \n",
      " 7   age              42825 non-null  float64       \n",
      " 8   gender           42825 non-null  object        \n",
      " 9   marital_status   41192 non-null  object        \n",
      " 10  insurance        42825 non-null  object        \n",
      " 11  diagnosis        42824 non-null  object        \n",
      " 12  text             42825 non-null  object        \n",
      " 13  next_readmit_dt  42825 non-null  float64       \n",
      " 14  target           42825 non-null  int32         \n",
      " 15  clean            42825 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(2), int32(1), int64(3), object(8)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>first_careunit</th>\n",
       "      <th>last_careunit</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>insurance</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>text</th>\n",
       "      <th>next_readmit_dt</th>\n",
       "      <th>target</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>2101-10-20 19:08:00</td>\n",
       "      <td>2101-10-31 13:58:00</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>76.526788</td>\n",
       "      <td>M</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>HYPOTENSION</td>\n",
       "      <td>Admission Date:  [**2101-10-20**]     Discharg...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>admit hypotension urine illness hospitalize ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>2191-03-16 00:28:00</td>\n",
       "      <td>2191-03-23 18:41:00</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>47.845044</td>\n",
       "      <td>F</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>Private</td>\n",
       "      <td>FEVER,DEHYDRATION,FAILURE TO THRIVE</td>\n",
       "      <td>Admission Date:  [**2191-3-16**]     Discharge...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>shortness breath fever illness human immunodef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>2175-05-30 07:15:00</td>\n",
       "      <td>2175-06-15 16:00:00</td>\n",
       "      <td>SICU</td>\n",
       "      <td>SICU</td>\n",
       "      <td>65.940670</td>\n",
       "      <td>F</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>CHRONIC RENAL FAILURE/SDA</td>\n",
       "      <td>Admission Date: [**2175-5-30**]        Dischar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>end stage renal disease admit transplant surge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  subject_id  hadm_id           admittime           dischtime  \\\n",
       "0      0           3   145834 2101-10-20 19:08:00 2101-10-31 13:58:00   \n",
       "1      1           4   185777 2191-03-16 00:28:00 2191-03-23 18:41:00   \n",
       "2      2           6   107064 2175-05-30 07:15:00 2175-06-15 16:00:00   \n",
       "\n",
       "  first_careunit last_careunit        age gender marital_status insurance  \\\n",
       "0           MICU          MICU  76.526788      M        MARRIED  Medicare   \n",
       "1           MICU          MICU  47.845044      F         SINGLE   Private   \n",
       "2           SICU          SICU  65.940670      F        MARRIED  Medicare   \n",
       "\n",
       "                             diagnosis  \\\n",
       "0                          HYPOTENSION   \n",
       "1  FEVER,DEHYDRATION,FAILURE TO THRIVE   \n",
       "2            CHRONIC RENAL FAILURE/SDA   \n",
       "\n",
       "                                                text  next_readmit_dt  target  \\\n",
       "0  Admission Date:  [**2101-10-20**]     Discharg...              0.0       0   \n",
       "1  Admission Date:  [**2191-3-16**]     Discharge...              0.0       0   \n",
       "2  Admission Date: [**2175-5-30**]        Dischar...              0.0       0   \n",
       "\n",
       "                                               clean  \n",
       "0  admit hypotension urine illness hospitalize ho...  \n",
       "1  shortness breath fever illness human immunodef...  \n",
       "2  end stage renal disease admit transplant surge...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[[\"diagnosis\", \"clean\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "macronum=sorted(set(df['target']))\n",
    "macro_to_id = dict((note, number) for number, note in enumerate(macronum))\n",
    "\n",
    "def fun(i):\n",
    "    return macro_to_id[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42825 entries, 0 to 42824\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   diagnosis  42824 non-null  object\n",
      " 1   clean      42825 non-null  object\n",
      " 2   target     42825 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1003.8+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-75c5d8457749>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['target']=df['target'].apply(fun)\n"
     ]
    }
   ],
   "source": [
    "df['target']=df['target'].apply(fun)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for idx in df['target']:\n",
    "    labels.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_proc(df, text_name) :\n",
    "\n",
    "    texts = []\n",
    "\n",
    "    for idx in range(df[text_name].shape[0]):\n",
    "        texts.append(df[text_name][idx])\n",
    "    \n",
    "    # Transformation des tokens des textes en sequences de tokens\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    seq = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    return seq, df, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Tokens 202601\n",
      "Shape of Data Sequence Tensor: (42825, 1000)\n",
      "Shape of Label Tensor: (42825, 2)\n"
     ]
    }
   ],
   "source": [
    "seq, df, word_index = pre_proc(df, 'clean')\n",
    "\n",
    "print('Number of Unique Tokens',len(word_index))\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of Data Sequence Tensor:', seq.shape)\n",
    "print('Shape of Label Tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(seq, labels, test_size = 0.2, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 2000000 word vectors in FastText 4GB.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('F:/Dropbox/Travaux_JAOTOMBO/These_Sante_Publique/NLP/Embeddings/fasttext_fr/cc.fr.300.vec/cc.fr.300.vec',encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Total %s word vectors in FastText 4GB.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() :\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    \n",
    "    bigram_branch = Conv1D(filters=128, kernel_size=2, padding='valid', activation='relu', strides=1)(embedded_sequences)\n",
    "    bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "    \n",
    "    trigram_branch = Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu', strides=1)(embedded_sequences)\n",
    "    trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "    \n",
    "    fourgram_branch = Conv1D(filters=128, kernel_size=4, padding='valid', activation='relu', strides=1)(embedded_sequences)\n",
    "    fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "    \n",
    "    fivegram_branch = Conv1D(filters=128, kernel_size=4, padding='valid', activation='relu', strides=1)(embedded_sequences)\n",
    "    fivegram_branch = GlobalMaxPooling1D()(fivegram_branch)\n",
    "    \n",
    "    merged = concatenate([bigram_branch, trigram_branch, fourgram_branch, fivegram_branch], axis=1)\n",
    "    \n",
    "    merged = Dense(256, activation='relu')(merged)\n",
    "    merged = Dropout(0.2)(merged)\n",
    "    merged = Dense(len(macronum))(merged)\n",
    "    \n",
    "    output = Activation('sigmoid')(merged)\n",
    "    model = Model(inputs=[sequence_input], outputs=[output])\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc',tf.keras.metrics.AUC()])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=None, stratify=y_train_full)\n",
    "\n",
    "# Fit the model to the training data\n",
    "checkpoint_cb = ModelCheckpoint(\"Yoon_Kim_Model.hdf5\",monitor='val_acc', verbose=1, save_best_only=True)\n",
    "early_stopping_cb = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=2, callbacks=[checkpoint_cb, early_stopping_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 2s 9ms/step\n",
      "268/268 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "y_pred = model.predict(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores\n",
    "auc_score = roc_auc_score(y_test[:,1], y_pred_proba)\n",
    "accuracy_score  = accuracy_score(y_test[:,1], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9064798598949212 0.6166681100101186\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score, auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
