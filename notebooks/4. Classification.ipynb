{"cells":[{"cell_type":"markdown","id":"39c464e0","metadata":{"id":"39c464e0"},"source":["# Classification"]},{"cell_type":"code","execution_count":19,"id":"dadefae3","metadata":{"id":"dadefae3","executionInfo":{"status":"ok","timestamp":1647534707788,"user_tz":-60,"elapsed":9,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["# Import libraries\n","import numpy as np\n","import pandas as pd\n","import os\n","import random\n","import dill\n","import pickle\n","from tabulate import tabulate\n","\n","import sys\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.metrics import roc_auc_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","import lightgbm as lgb\n","try:\n","  from catboost import CatBoostClassifier\n","except:\n","  !pip install catboost\n","  from catboost import CatBoostClassifier\n","\n","import time\n","from datetime import timedelta"]},{"cell_type":"code","execution_count":20,"id":"2205b1e7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2205b1e7","executionInfo":{"status":"ok","timestamp":1647534711530,"user_tz":-60,"elapsed":3749,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}},"outputId":"2f7ba12e-2bb2-4915-e2c1-0774539be127"},"outputs":[{"output_type":"stream","name":"stdout","text":["We're running Colab\n","Colab: mounting Google drive on  /content/gdrive\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive/MIMIC-III Text Mining/mimim_iii_readmission\n"]}],"source":["try:\n","  from google.colab import drive\n","  IN_COLAB=True\n","except:\n","  IN_COLAB=False\n","\n","if IN_COLAB:\n","  print(\"We're running Colab\")\n","\n","if IN_COLAB:  \n","  # Mount the Google Drive at mount\n","  mount='/content/gdrive'\n","  print(\"Colab: mounting Google drive on \", mount)\n","  # connect your colab with the drive\n","  drive.mount(mount)\n","\n"," # Switch to the directory on the Google Drive that you want to use\n","  import os\n","  path_to_repo = mount + \"/My Drive/MIMIC-III Text Mining/mimim_iii_readmission\"\n","\n","else:\n","   path_to_repo = os.path.dirname(os.getcwd())\n","\n","  \n","print(path_to_repo)"]},{"cell_type":"code","execution_count":21,"id":"729f43fa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"729f43fa","executionInfo":{"status":"ok","timestamp":1647534711530,"user_tz":-60,"elapsed":10,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}},"outputId":"e047a708-776e-4564-d833-910a3e5e425c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/MIMIC-III Text Mining/mimim_iii_readmission/data/\n"]}],"source":["path_to_data = os.path.join(path_to_repo, \"data\",\"\")\n","print(path_to_data)"]},{"cell_type":"code","execution_count":22,"id":"a17b264d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a17b264d","executionInfo":{"status":"ok","timestamp":1647534711531,"user_tz":-60,"elapsed":8,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}},"outputId":"5c2672cf-53a8-4819-adcf-8118369c1d71"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/MIMIC-III Text Mining/mimim_iii_readmission/data/processed/\n"]}],"source":["path_to_processed = os.path.join(path_to_data,\"processed\",\"\")\n","os.makedirs(path_to_processed, exist_ok=True) # we create the directory if it does not exist\n","print(path_to_processed)"]},{"cell_type":"code","execution_count":23,"id":"2d03c45a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2d03c45a","executionInfo":{"status":"ok","timestamp":1647534711531,"user_tz":-60,"elapsed":7,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}},"outputId":"cbf6b245-6ed3-4859-a33c-40a3de63d3fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/MIMIC-III Text Mining/mimim_iii_readmission/data/models/\n"]}],"source":["path_to_models = os.path.join(path_to_data,\"models\",\"\")\n","os.makedirs(path_to_models, exist_ok=True) # we create the directory if it does not exist\n","print(path_to_models)"]},{"cell_type":"code","execution_count":24,"id":"52eba6db","metadata":{"id":"52eba6db","executionInfo":{"status":"ok","timestamp":1647534711531,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["# PARAMETERS\n","\n","session_seed = 42 # set seed for our session\n","include_val = False # set to True if we want to also create a validation set\n","\n","random.seed(session_seed)"]},{"cell_type":"markdown","id":"6cbb49c6","metadata":{"id":"6cbb49c6"},"source":["## Train the Models"]},{"cell_type":"code","execution_count":25,"id":"5677bd47","metadata":{"id":"5677bd47","executionInfo":{"status":"ok","timestamp":1647534711532,"user_tz":-60,"elapsed":6,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["def load_datasets(method, include_val = True, target = False):\n","    \"\"\"\n","    Function to load train, test and validation set based on the chosen method\n","    method: string for the processing method we want to load\n","    include_diag: if we want to load the dataframes with the diagnosis text, default True\n","    include_test: if we want to load also the test set, default True\n","    target: if we are importing our target variables\n","    \"\"\"\n","    global path_to_processed\n","    if target == True: \n","        target = 'y_'\n","    else: \n","        target = ''\n","    # load it back\n","    train = pd.read_feather(f'{path_to_processed}{target}train_{method}')\n","    test = pd.read_feather(f'{path_to_processed}{target}test_{method}')\n","    if include_val == True:\n","        val = pd.read_feather(f'{path_to_processed}{target}val_{method}')\n","    else: val = []\n","    return train, test, val"]},{"cell_type":"code","execution_count":26,"id":"94c3a0cd","metadata":{"id":"94c3a0cd","executionInfo":{"status":"ok","timestamp":1647534712028,"user_tz":-60,"elapsed":502,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["y_train, y_test, y_val = load_datasets(method = '', include_val = include_val, target = True)"]},{"cell_type":"code","execution_count":27,"id":"9dd0a6f7","metadata":{"id":"9dd0a6f7","executionInfo":{"status":"ok","timestamp":1647534712029,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["# initialize a dictionary for the results of all the models\n","train_roc = {}\n","val_roc = {}\n","test_roc = {}"]},{"cell_type":"code","execution_count":28,"id":"be35822f","metadata":{"id":"be35822f","executionInfo":{"status":"ok","timestamp":1647534712029,"user_tz":-60,"elapsed":4,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["model_dict = {\n","    'log_reg': LogisticRegression(solver = \"saga\", penalty = 'l1', random_state = session_seed, n_jobs = -1) # default penalty is l2, we do lasso\n","    #, 'dec_tree': DecisionTreeClassifier(random_state = session_seed)\n","    #, 'bag_tree': BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 10, random_state = session_seed, n_jobs = -1)\n","    , 'rand_for': RandomForestClassifier(random_state = session_seed, n_jobs = -1)\n","    #, 'gboost': GradientBoostingClassifier(random_state = session_seed)\n","    , 'lightgbm': lgb.LGBMClassifier(random_state = 42, n_jobs = -1, deterministic = True)\n","    #, 'catboost': CatBoostClassifier(random_seed = 42)\n","}"]},{"cell_type":"code","execution_count":29,"id":"f0a83e3e","metadata":{"id":"f0a83e3e","executionInfo":{"status":"ok","timestamp":1647534712030,"user_tz":-60,"elapsed":5,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["method_list = ['frequency', 'onehot','tf_idf', 'svd', 'lda']"]},{"cell_type":"code","execution_count":30,"id":"a6553d5b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6553d5b","executionInfo":{"status":"ok","timestamp":1647534904660,"user_tz":-60,"elapsed":192634,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}},"outputId":"517754be-646d-422a-c5bd-ace0d84f521c"},"outputs":[{"output_type":"stream","name":"stdout","text":["log_reg\n","frequency\n","Model already trained\n","0:00:00.012054\n","ROC Training Set: 0.8390933835663675\n","ROC Test Set: 0.6114780865887829\n","onehot\n","Model already trained\n","0:00:00.015086\n","ROC Training Set: 0.9953941941261862\n","ROC Test Set: 0.6112127938463157\n","tf_idf\n","Model already trained\n","0:00:00.005361\n","ROC Training Set: 0.749163847407937\n","ROC Test Set: 0.7065949930262612\n","svd\n","Model already trained\n","0:00:00.003367\n","ROC Training Set: 0.6267888357296673\n","ROC Test Set: 0.5930386261619245\n","lda\n","Model successfully trained\n","Model saved\n","0:00:01.758939\n","ROC Training Set: 0.6836896024523876\n","ROC Test Set: 0.6809031210883738\n","rand_for\n","frequency\n","Model already trained\n","0:00:00.206843\n","ROC Training Set: 1.0\n","ROC Test Set: 0.6933003662885361\n","onehot\n","Model already trained\n","0:00:00.097878\n","ROC Training Set: 1.0\n","ROC Test Set: 0.7035766536850084\n","tf_idf\n","Model already trained\n","0:00:00.104357\n","ROC Training Set: 1.0\n","ROC Test Set: 0.6391734954556507\n","svd\n","Model already trained\n","0:00:00.063075\n","ROC Training Set: 1.0\n","ROC Test Set: 0.6463061791985576\n","lda\n","Model successfully trained\n","Model saved\n","0:00:31.379253\n","ROC Training Set: 1.0\n","ROC Test Set: 0.6722638052575945\n","lightgbm\n","frequency\n","Model already trained\n","0:00:00.012517\n","ROC Training Set: 0.9956994861446009\n","ROC Test Set: 0.68991615365202\n","onehot\n","Model already trained\n","0:00:00.013418\n","ROC Training Set: 0.9962172203717901\n","ROC Test Set: 0.6892882172650671\n","tf_idf\n","Model already trained\n","0:00:00.028971\n","ROC Training Set: 0.9996915092451265\n","ROC Test Set: 0.694925342008483\n","svd\n","Model already trained\n","0:00:00.010804\n","ROC Training Set: 0.9976822704873453\n","ROC Test Set: 0.6481078629539215\n","lda\n","Model successfully trained\n","Model saved\n","0:00:03.145542\n","ROC Training Set: 0.9813386147257954\n","ROC Test Set: 0.682113548062048\n"]}],"source":["for model_name, model in model_dict.items(): \n","    print(model_name)\n","    # initialize lists with the results\n","    results_train = []\n","    results_val = []\n","    results_test = []\n","    for method in method_list:\n","        print(method)\n","        train, test, val = load_datasets(method, include_val = include_val) # we load the dataset we want to use\n","        start_time = time.monotonic()\n","        try:\n","            with open(f'{path_to_models}_{model_name}_{method}', 'rb') as file:\n","                model = dill.load(file)\n","            print('Model already trained')\n","        except:\n","            model.fit(train, y_train) # we fit our model\n","            print('Model successfully trained')\n","            with open(f'{path_to_models}_{model_name}_{method}', 'wb') as file: # and save the fitted model\n","                dill.dump(model, file)\n","            print('Model saved')\n","        end_time = time.monotonic()\n","        print(timedelta(seconds=end_time - start_time))\n","        roc_train = roc_auc_score(y_train.target, model.predict_proba(train)[:, 1])\n","        roc_test = roc_auc_score(y_test.target, model.predict_proba(test)[:, 1])\n","        results_train.append(roc_train) # append the ROC score\n","        results_test.append(roc_test)\n","        print('ROC Training Set: {}'.format(roc_train))\n","        print('ROC Test Set: {}'.format(roc_test))\n","        if include_val == True:\n","            roc_val = roc_auc_score(y_val.target, model.predict_proba(val)[:, 1])\n","            results_val.append(roc_val)\n","            print('ROC Validation Set: {}'.format(roc_val))\n","    # finally we add the result lists to our dictionary\n","    train_roc[model_name] = results_train\n","    val_roc[model_name] = results_val\n","    test_roc[model_name] = results_test"]},{"cell_type":"code","execution_count":32,"id":"17dc9f57","metadata":{"id":"17dc9f57","executionInfo":{"status":"ok","timestamp":1647534912432,"user_tz":-60,"elapsed":651,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["# Then we save all our results\n","with open(f'{path_to_models}train_results.pkl', 'wb') as file:\n","    pickle.dump(train_roc, file)\n","with open(f'{path_to_models}val_results.pkl', 'wb') as file:\n","    pickle.dump(val_roc, file)\n","if include_val == True:\n","    with open(f'{path_to_models}test_results.pkl', 'wb') as file:\n","        pickle.dump(test_roc, file)"]},{"cell_type":"markdown","id":"36537b18","metadata":{"id":"36537b18"},"source":["## Display Results"]},{"cell_type":"code","execution_count":33,"id":"c07f51f2","metadata":{"id":"c07f51f2","executionInfo":{"status":"ok","timestamp":1647534913423,"user_tz":-60,"elapsed":14,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["def get_final_res_list(dict):\n","    \"\"\"\n","    Function to transform our results to a list of list usable by the tabulate function\n","    \"\"\"\n","    results = []\n","    for key, values in dict.items():\n","        new_res = [[key], values]\n","        flat_list = [item for sublist in new_res for item in sublist]\n","        results.append(flat_list)\n","    return results"]},{"cell_type":"code","execution_count":34,"id":"a3f35b3a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3f35b3a","executionInfo":{"status":"ok","timestamp":1647534913424,"user_tz":-60,"elapsed":12,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}},"outputId":"8925b0e1-364b-42d6-9804-7d5bfbd8cf9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["            frequency    onehot    tf_idf       svd       lda\n","--------  -----------  --------  --------  --------  --------\n","log_reg      0.839093  0.995394  0.749164  0.626789  0.68369\n","rand_for     1         1         1         1         1\n","lightgbm     0.995699  0.996217  0.999692  0.997682  0.981339\n"]}],"source":["train_results = get_final_res_list(train_roc)\n","print(tabulate(train_results, headers = method_list))"]},{"cell_type":"code","execution_count":35,"id":"3ec66887","metadata":{"id":"3ec66887","executionInfo":{"status":"ok","timestamp":1647534913425,"user_tz":-60,"elapsed":11,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}}},"outputs":[],"source":["if include_val:\n","    val_results = get_final_res_list(val_roc)\n","    print(tabulate(val_results, headers = method_list))"]},{"cell_type":"code","execution_count":36,"id":"0413986b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0413986b","executionInfo":{"status":"ok","timestamp":1647534913426,"user_tz":-60,"elapsed":11,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"}},"outputId":"35ca3f5f-696d-4d54-a365-77a4471cad7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["            frequency    onehot    tf_idf       svd       lda\n","--------  -----------  --------  --------  --------  --------\n","log_reg      0.611478  0.611213  0.706595  0.593039  0.680903\n","rand_for     0.6933    0.703577  0.639173  0.646306  0.672264\n","lightgbm     0.689916  0.689288  0.694925  0.648108  0.682114\n"]}],"source":["test_results = get_final_res_list(test_roc)\n","print(tabulate(test_results, headers = method_list))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"4. Classification.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}