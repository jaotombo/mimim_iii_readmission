{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a7fe9b",
   "metadata": {},
   "source": [
    "# Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c62d2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import dill\n",
    "import pickle\n",
    "from tabulate import tabulate\n",
    "\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from hmeasure import h_score\n",
    "try:\n",
    "  from catboost import CatBoostClassifier\n",
    "except:\n",
    "  !pip install catboost\n",
    "  from catboost import CatBoostClassifier\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112554ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca9\\Documents\\MIMIC-III Text Mining\\mimim_iii_readmission\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB=True\n",
    "except:\n",
    "  IN_COLAB=False\n",
    "\n",
    "if IN_COLAB:\n",
    "  print(\"We're running Colab\")\n",
    "\n",
    "if IN_COLAB:  \n",
    "  # Mount the Google Drive at mount\n",
    "  mount='/content/gdrive'\n",
    "  print(\"Colab: mounting Google drive on \", mount)\n",
    "  # connect your colab with the drive\n",
    "  drive.mount(mount)\n",
    "\n",
    " # Switch to the directory on the Google Drive that you want to use\n",
    "  import os\n",
    "  path_to_repo = mount + \"/My Drive/MIMIC-III Text Mining/mimim_iii_readmission\"\n",
    "\n",
    "else:\n",
    "   path_to_repo = os.path.dirname(os.getcwd())\n",
    "\n",
    "  \n",
    "print(path_to_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55373891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca9\\Documents\\MIMIC-III Text Mining\\mimim_iii_readmission\\data\\\n"
     ]
    }
   ],
   "source": [
    "path_to_data = os.path.join(path_to_repo, \"data\",\"\")\n",
    "print(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28c3325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca9\\Documents\\MIMIC-III Text Mining\\mimim_iii_readmission\\data\\processed\\\n"
     ]
    }
   ],
   "source": [
    "path_to_processed = os.path.join(path_to_data,\"processed\",\"\")\n",
    "os.makedirs(path_to_processed, exist_ok=True) # we create the directory if it does not exist\n",
    "print(path_to_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9ec2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca9\\Documents\\MIMIC-III Text Mining\\mimim_iii_readmission\\data\\models\\\n"
     ]
    }
   ],
   "source": [
    "path_to_models = os.path.join(path_to_data,\"models\",\"\")\n",
    "os.makedirs(path_to_models, exist_ok=True) # we create the directory if it does not exist\n",
    "print(path_to_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb850e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luca9\\Documents\\MIMIC-III Text Mining\\mimim_iii_readmission\\data\\figures\\\n"
     ]
    }
   ],
   "source": [
    "path_to_figures = os.path.join(path_to_data,\"figures\",\"\")\n",
    "os.makedirs(path_to_figures, exist_ok=True) # we create the directory if it does not exist\n",
    "print(path_to_figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aa596ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "session_seed = 42 # set seed for our session\n",
    "include_val = False # set to True if we want to also create a validation set\n",
    "tune_models = True # set to True if we want to perform parameter tuning\n",
    "\n",
    "lemmatize = True # set to false if we want to do stemming\n",
    "lemma_tag = str(np.where(lemmatize, \"_lemma\",\"\"))\n",
    "spacy = True\n",
    "if spacy: lemma_tag = str(np.where(lemmatize, \"_lemma_spacy\",\"\"))\n",
    "\n",
    "seed_tag = f'_{session_seed}'\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''\n",
    "\n",
    "random.seed(session_seed)\n",
    "\n",
    "scoring = 'roc_auc' # what score should we use for permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef54cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(method, include_val = True, target = False):\n",
    "    \"\"\"\n",
    "    Function to load train, test and validation set based on the chosen method\n",
    "    method: string for the processing method we want to load\n",
    "    include_diag: if we want to load the dataframes with the diagnosis text, default True\n",
    "    include_test: if we want to load also the test set, default True\n",
    "    target: if we are importing our target variables\n",
    "    \"\"\"\n",
    "    global path_to_processed\n",
    "    if target == True: \n",
    "        target = 'y_'\n",
    "    else: \n",
    "        target = ''\n",
    "    # load it back\n",
    "    train = pd.read_feather(f'{path_to_processed}{target}train_{method}{seed_tag}{lemma_tag}')\n",
    "    test = pd.read_feather(f'{path_to_processed}{target}test_{method}{seed_tag}{lemma_tag}')\n",
    "    if include_val == True:\n",
    "        val = pd.read_feather(f'{path_to_processed}{target}val_{method}{seed_tag}{lemma_tag}')\n",
    "    else: val = []\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13fc5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test, y_val = load_datasets(method = '', include_val = include_val, target = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d31d1",
   "metadata": {},
   "source": [
    "# Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb30ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_perm_importance(X_valid, result) :\n",
    "    flabels = X_valid.columns\n",
    "    impvalues = 100*result.importances_mean/np.max(result.importances_mean)\n",
    "    return pd.DataFrame({\"features\": flabels, \"importance\":impvalues}).sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aa9c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that saves figures\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    # The path of the figures folder ./Figures/fig_id.png (fig_id is a variable that you specify \n",
    "    # when you call the function)\n",
    "    path = os.path.join(path_to_figures, fig_id + \".png\") \n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3784584",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36539820",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'frequency'\n",
    "train, test, val = load_datasets(method, include_val = include_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24fbd6",
   "metadata": {},
   "source": [
    "### GBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd0f785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gboost'\n",
    "tune_models = False\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d614d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652eb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c98d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a7872",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67045273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'catboost'\n",
    "tune_models = False\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fdb6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48282b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cccd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f635030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283e3b5",
   "metadata": {},
   "source": [
    "## OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3c478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'onehot'\n",
    "train, test, val = load_datasets(method, include_val = include_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc7f5a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1b934fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'rand_for'\n",
    "tune_models = True\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd90c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8779ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e643be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69053b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461da2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150c090",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa0275c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'lightgbm'\n",
    "tune_models = True\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128adec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b593e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d365271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9379c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efa04de",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1439a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'tf_idf'\n",
    "train, test, val = load_datasets(method, include_val = include_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc19a5",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8ce82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'lightgbm'\n",
    "tune_models = True\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e033da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f570d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c813bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15e39a",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc2c0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'catboost'\n",
    "tune_models = False\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8bdfd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c538b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fda890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fff819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf90fb0",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0848b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'svd'\n",
    "train, test, val = load_datasets(method, include_val = include_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74348eab",
   "metadata": {},
   "source": [
    "### GBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d14ebcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gboost'\n",
    "tune_models = False\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d89d712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eca474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d9c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e546a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa4cb8",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ad5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'lightgbm'\n",
    "tune_models = True\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82f5f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd70075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa28c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1156cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709fb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356bd58d",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d519a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'lda'\n",
    "train, test, val = load_datasets(method, include_val = include_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08480d6a",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1c94505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'lightgbm'\n",
    "tune_models = True\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2345a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04047e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f47df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bce44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df06f0c",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88f68ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'catboost'\n",
    "tune_models = False\n",
    "\n",
    "if tune_models:\n",
    "  tune_tag = '_tuned'\n",
    "else:\n",
    "  tune_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec04ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path_to_models}_{model}_{method}{seed_tag}{lemma_tag}', 'rb') as file:\n",
    "    estimator = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea4f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_train = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_train = permutation_importance(estimator, train, y_train, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659155af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(train, import_train)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}train_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aaf3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "try:\n",
    "    with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'rb') as file:\n",
    "        import_test = pickle.load(file)\n",
    "    print('Importance loaded')\n",
    "except:\n",
    "    %time import_test = permutation_importance(estimator, test, y_val, n_jobs = -1, scoring = scoring, random_state = session_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_perm_importance(test, import_test)\n",
    "df_imp[:30].plot(x=\"features\", y=\"importance\", kind=\"barh\", figsize = (12,10), legend = False).invert_yaxis()\n",
    "save_fig(f'perm_imp_{method}_{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca661b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we save all our results\n",
    "with open(f'{path_to_models}test_imp{model}{method}{lemma_tag}.pkl', 'wb') as file:\n",
    "    pickle.dump(import_test, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
