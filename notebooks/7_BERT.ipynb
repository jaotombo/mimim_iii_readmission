{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39c464e0",
   "metadata": {
    "id": "39c464e0"
   },
   "source": [
    "# Classification - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d08adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# First install package from terminal:\n",
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install autogluon  # autogluon==0.4.1\n",
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadefae3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dadefae3",
    "outputId": "e9d79146-ee91-4e19-f7c9-27b4d2a9727d"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import dill\n",
    "import pickle\n",
    "from tabulate import tabulate\n",
    "\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from autogluon.text import TextPredictor\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertModel, BertConfig, BertForPreTraining, BertForSequenceClassification, pipeline\n",
    "import lime\n",
    "import lime.lime_text\n",
    "\n",
    "try:\n",
    "    from hmeasure import h_score\n",
    "except:\n",
    "    !pip install hmeasure\n",
    "    from hmeasure import h_score\n",
    "\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2205b1e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2205b1e7",
    "outputId": "e4543a9c-c463-4fc2-b393-e42fd55b2a1a"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB=True\n",
    "except:\n",
    "  IN_COLAB=False\n",
    "\n",
    "if IN_COLAB:\n",
    "  print(\"We're running Colab\")\n",
    "\n",
    "if IN_COLAB:  \n",
    "  # Mount the Google Drive at mount\n",
    "  mount='/content/gdrive'\n",
    "  print(\"Colab: mounting Google drive on \", mount)\n",
    "  # connect your colab with the drive\n",
    "  drive.mount(mount)\n",
    "\n",
    " # Switch to the directory on the Google Drive that you want to use\n",
    "  import os\n",
    "  path_to_repo = mount + \"/My Drive/MIMIC-III Text Mining/mimim_iii_readmission\"\n",
    "\n",
    "else:\n",
    "   path_to_repo = os.path.dirname(os.getcwd())\n",
    "\n",
    "  \n",
    "print(path_to_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eba6db",
   "metadata": {
    "id": "52eba6db"
   },
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "test_proportion = 0.2\n",
    "val_proportion = 0.1\n",
    "\n",
    "session_seed = 42 # set seed for our session\n",
    "include_val = False # set to True if we want to also create a validation set\n",
    "tune_models = True # set to True if we want to perform parameter tuning\n",
    "\n",
    "icu_stays = True # set to TRUE if we want to have only ICU stays\n",
    "lemmatize = True # set to false if we want to do stemming\n",
    "lemma_tag = str(np.where(lemmatize, \"_lemma\",\"\"))\n",
    "heavier_proc = True # if we want a heavier processing\n",
    "if heavier_proc:\n",
    "    heavier_tag = '_heavier'\n",
    "else:\n",
    "    heavier_tag = ''\n",
    "    \n",
    "spacy = True\n",
    "if spacy: lemma_tag = str(np.where(lemmatize, \"_lemma_spacy\",\"\"))\n",
    "\n",
    "seed_tag = f'_{session_seed}'\n",
    "\n",
    "halving = True # if we want to perform halving tune\n",
    "if tune_models:\n",
    "    if halving:\n",
    "        tune_tag = '_tuned_halv'\n",
    "    else:\n",
    "        tune_tag = '_tuned'   \n",
    "else:\n",
    "    tune_tag = ''\n",
    "\n",
    "random.seed(session_seed)\n",
    "\n",
    "med_7 = False # set to True if we want to use our Med7 preprocessing\n",
    "\n",
    "if med_7:\n",
    "    med_tag = \"_med7\"\n",
    "else:\n",
    "    med_tag = ''\n",
    "    \n",
    "feat_select = False # select True if we want to use Lasso as a feature selection method\n",
    "\n",
    "if feat_select:\n",
    "    feat_tag = \"_featselect\"\n",
    "else:\n",
    "    feat_tag = ''\n",
    "    \n",
    "expanded_def = True # set to True if we want to consider future readmissions and avoid using CMS \n",
    "\n",
    "if icu_stays == True:\n",
    "    icu_folder = 'icu_only'\n",
    "    if expanded_def:\n",
    "        icu_folder = 'expanded'\n",
    "else:\n",
    "    icu_folder = 'all_hosp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f43fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "729f43fa",
    "outputId": "40533f0b-c81c-469c-8954-24ac30711aea"
   },
   "outputs": [],
   "source": [
    "path_to_data = os.path.join(path_to_repo, \"data\", icu_folder,\"\")\n",
    "print(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b264d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a17b264d",
    "outputId": "12557a08-55b2-419f-e6f1-af8347719c31"
   },
   "outputs": [],
   "source": [
    "path_to_processed = os.path.join(path_to_data,\"processed\",\"\")\n",
    "os.makedirs(path_to_processed, exist_ok=True) # we create the directory if it does not exist\n",
    "print(path_to_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03c45a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d03c45a",
    "outputId": "566c6f43-ea46-4432-cc97-17031353915e"
   },
   "outputs": [],
   "source": [
    "path_to_models = os.path.join(path_to_data,\"models\",\"\")\n",
    "os.makedirs(path_to_models, exist_ok=True) # we create the directory if it does not exist\n",
    "print(path_to_models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51cf309d",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a7d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our dataset\n",
    "df = pd.read_feather(os.path.join(path_to_data,f\"df_cleaned{lemma_tag}{med_tag}{heavier_tag}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "train, test = train_test_split(df, test_size = test_proportion, random_state = session_seed, stratify = df.target)\n",
    "if include_val == True:\n",
    "    # furtherly split into validation and train\n",
    "    train, val = train_test_split(train, test_size = val_proportion, random_state = session_seed, stratify = train.target)\n",
    "else:\n",
    "    val = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb49c6",
   "metadata": {
    "id": "6cbb49c6"
   },
   "source": [
    "## Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "label = 'target'\n",
    "metric = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute other metrics\n",
    "def perf_evaluator(y_test, y_pred, y_pred_proba):\n",
    "    \"\"\" Function to display the main classification performance metrics \"\"\"\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    precision, recall, prc_th = precision_recall_curve(y_test, y_pred_proba)\n",
    "    prc_auc = auc(recall, precision)\n",
    "    return kappa, prc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the tabular predictor ensemble of models (include 'multimodal' hyperparameter)\n",
    "save_path = f'{path_to_models}text{seed_tag}{lemma_tag}{med_tag}{heavier_tag}{lemma_tag}'\n",
    "os.makedirs(save_path, exist_ok = True)\n",
    "\n",
    "try:\n",
    "  predictor = TextPredictor.load(save_path)\n",
    "  print(\"Model Loaded\")\n",
    "except:\n",
    "  print(\"Training Model\")\n",
    "  predictor = TextPredictor(label=label, eval_metric=metric, path=save_path)\n",
    "  predictor.fit(\n",
    "      train_data=train,\n",
    "      hyperparameters={\n",
    "          \"model.hf_text.checkpoint_name\": \"emilyalsentzer/Bio_ClinicalBERT\", \n",
    "      },\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance on the test set\n",
    "per_tab = predictor.evaluate(test, metrics=['roc_auc','f1','acc'])\n",
    "print(f\"\\nTest set performance:\\n{per_tab}\")\n",
    "# save the class and probability predictions\n",
    "y_pred = predictor.predict(test)\n",
    "y_pred_proba = predictor.predict_proba(test).iloc[:,1]\n",
    "perf = perf_evaluator(test['los_cat'], y_pred, y_pred_proba)\n",
    "perf_dict = {\"Cohen's Kappa\": perf[0], \"PRC AUC\": perf[1]}\n",
    "print(f\"\\nPerformance metrics:\\n{perf_dict}\")\n",
    "perf_dict.update(per_tab)\n",
    "\n",
    "# save performances\n",
    "df_perf = pd.DataFrame.from_dict(perf_dict, orient='index', columns=['performances'])\n",
    "df_perf.to_excel(path_to_models+f'text{seed_tag}{lemma_tag}{med_tag}{heavier_tag}{lemma_tag}/df_perf.xlsx')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "4. Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8fc10b2d10f9f16d25710b4d4512c52b634d4a9283a799a319e31d4f4e23ed6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
